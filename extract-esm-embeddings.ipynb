{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":116062,"databundleVersionId":14084779,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install duckdb --no-index --find-links=/kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/duck_pkg\n!pip install polars --no-index --find-links=/kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg\n#!pip install fair-esm --no-index --find-links=/kaggle/input/suman-fair-esm/kaggle/working/fair_esm-2.0.0-py3-none-any.whl","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport random\nimport pprint\nimport os\nimport duckdb as dd\nimport polars as pl","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U transformers datasets evaluate accelerate timm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#from transformers import AutoTokenizer, EsmForProteinFolding, EsmModel\nimport transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T04:51:27.509425Z","iopub.execute_input":"2025-11-25T04:51:27.510473Z","iopub.status.idle":"2025-11-25T04:51:33.362023Z","shell.execute_reply.started":"2025-11-25T04:51:27.510446Z","shell.execute_reply":"2025-11-25T04:51:33.361060Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"## Run this twice, first time, it will show error\nfrom transformers import AutoTokenizer, EsmForProteinFolding, EsmModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T04:52:09.739265Z","iopub.execute_input":"2025-11-25T04:52:09.740255Z","iopub.status.idle":"2025-11-25T04:52:09.744124Z","shell.execute_reply.started":"2025-11-25T04:52:09.740229Z","shell.execute_reply":"2025-11-25T04:52:09.743065Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"facebook/esmfold_v1\")\nmodel = EsmModel.from_pretrained(\"facebook/esmfold_v1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T04:52:51.345422Z","iopub.execute_input":"2025-11-25T04:52:51.346334Z","iopub.status.idle":"2025-11-25T04:53:56.248039Z","shell.execute_reply.started":"2025-11-25T04:52:51.346296Z","shell.execute_reply":"2025-11-25T04:53:56.246726Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/40.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"778940fb73e24312bb8e999d44590562"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbc98f30de234a8fbc633a5a6cb79da7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/121 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c59b5c33a56849d6a09feb02cfa5e08b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"282617b043404c328ba5929dc08585ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/8.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71fbc4b28f6b46efa26ffbd71b8bae46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/8.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f84d67d00584c7497e2fa71105eeae2"}},"metadata":{}},{"name":"stderr","text":"Some weights of EsmModel were not initialized from the model checkpoint at facebook/esmfold_v1 and are newly initialized: ['contact_head.regression.bias', 'contact_head.regression.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T04:55:03.469454Z","iopub.execute_input":"2025-11-25T04:55:03.469757Z","iopub.status.idle":"2025-11-25T04:55:03.477555Z","shell.execute_reply.started":"2025-11-25T04:55:03.469735Z","shell.execute_reply":"2025-11-25T04:55:03.476817Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"model.to(device)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T04:55:13.115171Z","iopub.execute_input":"2025-11-25T04:55:13.115536Z","iopub.status.idle":"2025-11-25T04:55:16.624861Z","shell.execute_reply.started":"2025-11-25T04:55:13.115508Z","shell.execute_reply":"2025-11-25T04:55:16.623989Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"EsmModel(\n  (embeddings): EsmEmbeddings(\n    (word_embeddings): Embedding(33, 2560, padding_idx=1)\n    (dropout): Dropout(p=0.0, inplace=False)\n  )\n  (encoder): EsmEncoder(\n    (layer): ModuleList(\n      (0-35): 36 x EsmLayer(\n        (attention): EsmAttention(\n          (self): EsmSelfAttention(\n            (query): Linear(in_features=2560, out_features=2560, bias=True)\n            (key): Linear(in_features=2560, out_features=2560, bias=True)\n            (value): Linear(in_features=2560, out_features=2560, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n            (rotary_embeddings): RotaryEmbedding()\n          )\n          (output): EsmSelfOutput(\n            (dense): Linear(in_features=2560, out_features=2560, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (LayerNorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n        )\n        (intermediate): EsmIntermediate(\n          (dense): Linear(in_features=2560, out_features=10240, bias=True)\n        )\n        (output): EsmOutput(\n          (dense): Linear(in_features=10240, out_features=2560, bias=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n        (LayerNorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (emb_layer_norm_after): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n  )\n  (pooler): EsmPooler(\n    (dense): Linear(in_features=2560, out_features=2560, bias=True)\n    (activation): Tanh()\n  )\n  (contact_head): EsmContactPredictionHead(\n    (regression): Linear(in_features=1440, out_features=1, bias=True)\n    (activation): Sigmoid()\n  )\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import os\n\noutput_dir = \"/kaggle/working/esm_embeddings\"\nos.makedirs(output_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T04:56:13.103068Z","iopub.execute_input":"2025-11-25T04:56:13.103483Z","iopub.status.idle":"2025-11-25T04:56:13.108627Z","shell.execute_reply.started":"2025-11-25T04:56:13.103444Z","shell.execute_reply":"2025-11-25T04:56:13.107297Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"!pip install biopython","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T04:57:03.316964Z","iopub.execute_input":"2025-11-25T04:57:03.317303Z","iopub.status.idle":"2025-11-25T04:57:10.164057Z","shell.execute_reply.started":"2025-11-25T04:57:03.317280Z","shell.execute_reply":"2025-11-25T04:57:10.162870Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting biopython\n  Downloading biopython-1.86-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->biopython) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->biopython) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->biopython) (2024.2.0)\nDownloading biopython-1.86-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: biopython\nSuccessfully installed biopython-1.86\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from Bio import SeqIO","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T04:57:16.836283Z","iopub.execute_input":"2025-11-25T04:57:16.836908Z","iopub.status.idle":"2025-11-25T04:57:16.954554Z","shell.execute_reply.started":"2025-11-25T04:57:16.836868Z","shell.execute_reply":"2025-11-25T04:57:16.953589Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"sequences = SeqIO.parse(\"/kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta\", \"fasta\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T05:19:38.834822Z","iopub.execute_input":"2025-11-25T05:19:38.835136Z","iopub.status.idle":"2025-11-25T05:19:38.839668Z","shell.execute_reply.started":"2025-11-25T05:19:38.835114Z","shell.execute_reply":"2025-11-25T05:19:38.838937Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"train_sequences_list = list(sequences)\nlen(train_sequences_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T05:19:41.380432Z","iopub.execute_input":"2025-11-25T05:19:41.380864Z","iopub.status.idle":"2025-11-25T05:19:42.570162Z","shell.execute_reply.started":"2025-11-25T05:19:41.380840Z","shell.execute_reply":"2025-11-25T05:19:42.569482Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"82404"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"last_record = train_sequences_list[-1]  # using Python's list tricks\nprint(last_record.id)\nprint(repr(last_record.seq))\nprint(len(last_record))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T05:20:09.458466Z","iopub.execute_input":"2025-11-25T05:20:09.458863Z","iopub.status.idle":"2025-11-25T05:20:09.464258Z","shell.execute_reply.started":"2025-11-25T05:20:09.458825Z","shell.execute_reply":"2025-11-25T05:20:09.463477Z"}},"outputs":[{"name":"stdout","text":"sp|Q9Y816|YOND_SCHPO\nSeq('MITEFIKSFLLFFFLPFFLSMPMIFATLGEFTDDQTHHYSTLPSCDLLLIRGEV...KLN')\n142\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"type(sequences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T04:58:41.458379Z","iopub.execute_input":"2025-11-25T04:58:41.459249Z","iopub.status.idle":"2025-11-25T04:58:41.465412Z","shell.execute_reply.started":"2025-11-25T04:58:41.459211Z","shell.execute_reply":"2025-11-25T04:58:41.464674Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Bio.SeqIO.FastaIO.FastaIterator"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"for record in sequences:\n    seq_id = record.id\n    sequence = str(record.seq)\n\n    # Tokenize the sequence\n    # The tokenizer adds special tokens (CLS and SEP) automatically\n    inputs = tokenizer(sequence, return_tensors='pt', padding=True, truncation=True)\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n\n    # Generate embeddings\n    with torch.no_grad():\n        output = model(**inputs)\n\n    # Extract embeddings\n    # We usually take the last hidden states\n    embeddings = output.last_hidden_state # Shape: (batch_size, sequence_length, hidden_size)\n\n    # To get a single fixed-size embedding for the whole protein (mean pooling), \n    # you can average over the sequence length dimension (excluding CLS/SEP if desired, though often included for simplicity)\n    # Here we average over all tokens in the sequence.\n    # Alternatively, you can use the representation of the CLS token\n    # sequence_level_embedding = output.pooler_output # This only works for certain model configurations\n    \n    # Mean pooling as an alternative to pooler_output\n    # Start from index 1 and end at index -1 to ignore CLS and SEP tokens if they exist, \n    # but the standard practice with ESM is often to include all or use the representation from a specific layer\n    # For simplicity, we can do mean pooling across the sequence dimension for now:\n    sequence_embeddings = embeddings.mean(dim=1).squeeze().cpu().numpy() # Shape: (hidden_size,)\n\n    # Save the embeddings\n    output_path = os.path.join(output_dir, f\"{seq_id}.pt\")\n    torch.save({'embeddings': sequence_embeddings}, output_path) # Save as a dictionary\n    print(f\"Saved embeddings for {seq_id} to {output_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T05:05:00.069154Z","iopub.execute_input":"2025-11-25T05:05:00.069497Z","iopub.status.idle":"2025-11-25T05:09:05.022887Z","shell.execute_reply.started":"2025-11-25T05:05:00.069471Z","shell.execute_reply":"2025-11-25T05:09:05.021472Z"}},"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"Saved embeddings for sp|A0A0C5B5G6|MOTSC_HUMAN to /kaggle/working/esm_embeddings/sp|A0A0C5B5G6|MOTSC_HUMAN.pt\nSaved embeddings for sp|A0JNW5|BLT3B_HUMAN to /kaggle/working/esm_embeddings/sp|A0JNW5|BLT3B_HUMAN.pt\nSaved embeddings for sp|A0JP26|POTB3_HUMAN to /kaggle/working/esm_embeddings/sp|A0JP26|POTB3_HUMAN.pt\nSaved embeddings for sp|A0PK11|CLRN2_HUMAN to /kaggle/working/esm_embeddings/sp|A0PK11|CLRN2_HUMAN.pt\nSaved embeddings for sp|A1A4S6|RHG10_HUMAN to /kaggle/working/esm_embeddings/sp|A1A4S6|RHG10_HUMAN.pt\nSaved embeddings for sp|A1A519|F170A_HUMAN to /kaggle/working/esm_embeddings/sp|A1A519|F170A_HUMAN.pt\nSaved embeddings for sp|A1L190|SYCE3_HUMAN to /kaggle/working/esm_embeddings/sp|A1L190|SYCE3_HUMAN.pt\nSaved embeddings for sp|A1L3X0|ELOV7_HUMAN to /kaggle/working/esm_embeddings/sp|A1L3X0|ELOV7_HUMAN.pt\nSaved embeddings for sp|A1X283|SPD2B_HUMAN to /kaggle/working/esm_embeddings/sp|A1X283|SPD2B_HUMAN.pt\nSaved embeddings for sp|A2A2Y4|FRMD3_HUMAN to /kaggle/working/esm_embeddings/sp|A2A2Y4|FRMD3_HUMAN.pt\nSaved embeddings for sp|A2RU14|TM218_HUMAN to /kaggle/working/esm_embeddings/sp|A2RU14|TM218_HUMAN.pt\nSaved embeddings for sp|A2RUB6|CCD66_HUMAN to /kaggle/working/esm_embeddings/sp|A2RUB6|CCD66_HUMAN.pt\nSaved embeddings for sp|A2RUC4|TYW5_HUMAN to /kaggle/working/esm_embeddings/sp|A2RUC4|TYW5_HUMAN.pt\nSaved embeddings for sp|A4D1B5|GSAP_HUMAN to /kaggle/working/esm_embeddings/sp|A4D1B5|GSAP_HUMAN.pt\nSaved embeddings for sp|A4GXA9|EME2_HUMAN to /kaggle/working/esm_embeddings/sp|A4GXA9|EME2_HUMAN.pt\nSaved embeddings for sp|A5D8V7|ODAD3_HUMAN to /kaggle/working/esm_embeddings/sp|A5D8V7|ODAD3_HUMAN.pt\nSaved embeddings for sp|A5PLL7|PEDS1_HUMAN to /kaggle/working/esm_embeddings/sp|A5PLL7|PEDS1_HUMAN.pt\nSaved embeddings for sp|A6BM72|MEG11_HUMAN to /kaggle/working/esm_embeddings/sp|A6BM72|MEG11_HUMAN.pt\nSaved embeddings for sp|A6H8Y1|BDP1_HUMAN to /kaggle/working/esm_embeddings/sp|A6H8Y1|BDP1_HUMAN.pt\nSaved embeddings for sp|A6NCS4|NKX26_HUMAN to /kaggle/working/esm_embeddings/sp|A6NCS4|NKX26_HUMAN.pt\nSaved embeddings for sp|A6NFY7|SDHF1_HUMAN to /kaggle/working/esm_embeddings/sp|A6NFY7|SDHF1_HUMAN.pt\nSaved embeddings for sp|A6NGG8|PCARE_HUMAN to /kaggle/working/esm_embeddings/sp|A6NGG8|PCARE_HUMAN.pt\nSaved embeddings for sp|A6NI61|MYMK_HUMAN to /kaggle/working/esm_embeddings/sp|A6NI61|MYMK_HUMAN.pt\nSaved embeddings for sp|A6NKB5|PCX2_HUMAN to /kaggle/working/esm_embeddings/sp|A6NKB5|PCX2_HUMAN.pt\nSaved embeddings for sp|A6NNB3|IFM5_HUMAN to /kaggle/working/esm_embeddings/sp|A6NNB3|IFM5_HUMAN.pt\nSaved embeddings for sp|A7E2V4|ZSWM8_HUMAN to /kaggle/working/esm_embeddings/sp|A7E2V4|ZSWM8_HUMAN.pt\nSaved embeddings for sp|A7MCY6|TBKB1_HUMAN to /kaggle/working/esm_embeddings/sp|A7MCY6|TBKB1_HUMAN.pt\nSaved embeddings for sp|A7MD48|SRRM4_HUMAN to /kaggle/working/esm_embeddings/sp|A7MD48|SRRM4_HUMAN.pt\nSaved embeddings for sp|A7XYQ1|SOBP_HUMAN to /kaggle/working/esm_embeddings/sp|A7XYQ1|SOBP_HUMAN.pt\nSaved embeddings for sp|A8MQ03|CRTP1_HUMAN to /kaggle/working/esm_embeddings/sp|A8MQ03|CRTP1_HUMAN.pt\nSaved embeddings for sp|A8MW99|MEI4_HUMAN to /kaggle/working/esm_embeddings/sp|A8MW99|MEI4_HUMAN.pt\nSaved embeddings for sp|A9UHW6|MI4GD_HUMAN to /kaggle/working/esm_embeddings/sp|A9UHW6|MI4GD_HUMAN.pt\nSaved embeddings for sp|B1AK53|ESPN_HUMAN to /kaggle/working/esm_embeddings/sp|B1AK53|ESPN_HUMAN.pt\nSaved embeddings for sp|B2RUY7|VWC2L_HUMAN to /kaggle/working/esm_embeddings/sp|B2RUY7|VWC2L_HUMAN.pt\nSaved embeddings for sp|B3KU38|IQIP1_HUMAN to /kaggle/working/esm_embeddings/sp|B3KU38|IQIP1_HUMAN.pt\nSaved embeddings for sp|B6A8C7|TARM1_HUMAN to /kaggle/working/esm_embeddings/sp|B6A8C7|TARM1_HUMAN.pt\nSaved embeddings for sp|B7U540|KCJ18_HUMAN to /kaggle/working/esm_embeddings/sp|B7U540|KCJ18_HUMAN.pt\nSaved embeddings for sp|C9JLW8|MCRI1_HUMAN to /kaggle/working/esm_embeddings/sp|C9JLW8|MCRI1_HUMAN.pt\nSaved embeddings for sp|C9JRZ8|AK1BF_HUMAN to /kaggle/working/esm_embeddings/sp|C9JRZ8|AK1BF_HUMAN.pt\nSaved embeddings for sp|D3W0D1|KLRF2_HUMAN to /kaggle/working/esm_embeddings/sp|D3W0D1|KLRF2_HUMAN.pt\nSaved embeddings for sp|E0CX11|STMP1_HUMAN to /kaggle/working/esm_embeddings/sp|E0CX11|STMP1_HUMAN.pt\nSaved embeddings for sp|O00115|DNS2A_HUMAN to /kaggle/working/esm_embeddings/sp|O00115|DNS2A_HUMAN.pt\nSaved embeddings for sp|O00116|ADAS_HUMAN to /kaggle/working/esm_embeddings/sp|O00116|ADAS_HUMAN.pt\nSaved embeddings for sp|O00159|MYO1C_HUMAN to /kaggle/working/esm_embeddings/sp|O00159|MYO1C_HUMAN.pt\nSaved embeddings for sp|O00161|SNP23_HUMAN to /kaggle/working/esm_embeddings/sp|O00161|SNP23_HUMAN.pt\nSaved embeddings for sp|O00165|HAX1_HUMAN to /kaggle/working/esm_embeddings/sp|O00165|HAX1_HUMAN.pt\nSaved embeddings for sp|O00168|PLM_HUMAN to /kaggle/working/esm_embeddings/sp|O00168|PLM_HUMAN.pt\nSaved embeddings for sp|O00214|LEG8_HUMAN to /kaggle/working/esm_embeddings/sp|O00214|LEG8_HUMAN.pt\nSaved embeddings for sp|O00237|RN103_HUMAN to /kaggle/working/esm_embeddings/sp|O00237|RN103_HUMAN.pt\nSaved embeddings for sp|O00254|PAR3_HUMAN to /kaggle/working/esm_embeddings/sp|O00254|PAR3_HUMAN.pt\nSaved embeddings for sp|O00268|TAF4_HUMAN to /kaggle/working/esm_embeddings/sp|O00268|TAF4_HUMAN.pt\nSaved embeddings for sp|O00291|HIP1_HUMAN to /kaggle/working/esm_embeddings/sp|O00291|HIP1_HUMAN.pt\nSaved embeddings for sp|O00300|TR11B_HUMAN to /kaggle/working/esm_embeddings/sp|O00300|TR11B_HUMAN.pt\nSaved embeddings for sp|O00322|UPK1A_HUMAN to /kaggle/working/esm_embeddings/sp|O00322|UPK1A_HUMAN.pt\nSaved embeddings for sp|O00329|PK3CD_HUMAN to /kaggle/working/esm_embeddings/sp|O00329|PK3CD_HUMAN.pt\nSaved embeddings for sp|O00330|ODPX_HUMAN to /kaggle/working/esm_embeddings/sp|O00330|ODPX_HUMAN.pt\nSaved embeddings for sp|O00337|S28A1_HUMAN to /kaggle/working/esm_embeddings/sp|O00337|S28A1_HUMAN.pt\nSaved embeddings for sp|O00400|ACATN_HUMAN to /kaggle/working/esm_embeddings/sp|O00400|ACATN_HUMAN.pt\nSaved embeddings for sp|O00409|FOXN3_HUMAN to /kaggle/working/esm_embeddings/sp|O00409|FOXN3_HUMAN.pt\nSaved embeddings for sp|O00422|SAP18_HUMAN to /kaggle/working/esm_embeddings/sp|O00422|SAP18_HUMAN.pt\nSaved embeddings for sp|O00444|PLK4_HUMAN to /kaggle/working/esm_embeddings/sp|O00444|PLK4_HUMAN.pt\nSaved embeddings for sp|O00453|LST1_HUMAN to /kaggle/working/esm_embeddings/sp|O00453|LST1_HUMAN.pt\nSaved embeddings for sp|O00462|MANBA_HUMAN to /kaggle/working/esm_embeddings/sp|O00462|MANBA_HUMAN.pt\nSaved embeddings for sp|O00478|BT3A3_HUMAN to /kaggle/working/esm_embeddings/sp|O00478|BT3A3_HUMAN.pt\nSaved embeddings for sp|O00487|PSDE_HUMAN to /kaggle/working/esm_embeddings/sp|O00487|PSDE_HUMAN.pt\nSaved embeddings for sp|O00505|IMA4_HUMAN to /kaggle/working/esm_embeddings/sp|O00505|IMA4_HUMAN.pt\nSaved embeddings for sp|O00506|STK25_HUMAN to /kaggle/working/esm_embeddings/sp|O00506|STK25_HUMAN.pt\nSaved embeddings for sp|O00507|USP9Y_HUMAN to /kaggle/working/esm_embeddings/sp|O00507|USP9Y_HUMAN.pt\nSaved embeddings for sp|O00560|SDCB1_HUMAN to /kaggle/working/esm_embeddings/sp|O00560|SDCB1_HUMAN.pt\nSaved embeddings for sp|O00591|GBRP_HUMAN to /kaggle/working/esm_embeddings/sp|O00591|GBRP_HUMAN.pt\nSaved embeddings for sp|O00622|CCN1_HUMAN to /kaggle/working/esm_embeddings/sp|O00622|CCN1_HUMAN.pt\nSaved embeddings for sp|O00624|NPT3_HUMAN to /kaggle/working/esm_embeddings/sp|O00624|NPT3_HUMAN.pt\nSaved embeddings for sp|O00635|TRI38_HUMAN to /kaggle/working/esm_embeddings/sp|O00635|TRI38_HUMAN.pt\nSaved embeddings for sp|O00712|NFIB_HUMAN to /kaggle/working/esm_embeddings/sp|O00712|NFIB_HUMAN.pt\nSaved embeddings for sp|O00746|NDKM_HUMAN to /kaggle/working/esm_embeddings/sp|O00746|NDKM_HUMAN.pt\nSaved embeddings for sp|O00748|EST2_HUMAN to /kaggle/working/esm_embeddings/sp|O00748|EST2_HUMAN.pt\nSaved embeddings for sp|O00762|UBE2C_HUMAN to /kaggle/working/esm_embeddings/sp|O00762|UBE2C_HUMAN.pt\nSaved embeddings for sp|O14497|ARI1A_HUMAN to /kaggle/working/esm_embeddings/sp|O14497|ARI1A_HUMAN.pt\nSaved embeddings for sp|O14503|BHE40_HUMAN to /kaggle/working/esm_embeddings/sp|O14503|BHE40_HUMAN.pt\nSaved embeddings for sp|O14508|SOCS2_HUMAN to /kaggle/working/esm_embeddings/sp|O14508|SOCS2_HUMAN.pt\nSaved embeddings for sp|O14519|CDKA1_HUMAN to /kaggle/working/esm_embeddings/sp|O14519|CDKA1_HUMAN.pt\nSaved embeddings for sp|O14524|NEMP1_HUMAN to /kaggle/working/esm_embeddings/sp|O14524|NEMP1_HUMAN.pt\nSaved embeddings for sp|O14548|CO72L_HUMAN to /kaggle/working/esm_embeddings/sp|O14548|CO72L_HUMAN.pt\nSaved embeddings for sp|O14561|ACPM_HUMAN to /kaggle/working/esm_embeddings/sp|O14561|ACPM_HUMAN.pt\nSaved embeddings for sp|O14613|BORG1_HUMAN to /kaggle/working/esm_embeddings/sp|O14613|BORG1_HUMAN.pt\nSaved embeddings for sp|O14618|CCS_HUMAN to /kaggle/working/esm_embeddings/sp|O14618|CCS_HUMAN.pt\nSaved embeddings for sp|O14638|ENPP3_HUMAN to /kaggle/working/esm_embeddings/sp|O14638|ENPP3_HUMAN.pt\nSaved embeddings for sp|O14640|DVL1_HUMAN to /kaggle/working/esm_embeddings/sp|O14640|DVL1_HUMAN.pt\nSaved embeddings for sp|O14654|IRS4_HUMAN to /kaggle/working/esm_embeddings/sp|O14654|IRS4_HUMAN.pt\nSaved embeddings for sp|O14657|TOR1B_HUMAN to /kaggle/working/esm_embeddings/sp|O14657|TOR1B_HUMAN.pt\nSaved embeddings for sp|O14744|ANM5_HUMAN to /kaggle/working/esm_embeddings/sp|O14744|ANM5_HUMAN.pt\nSaved embeddings for sp|O14756|H17B6_HUMAN to /kaggle/working/esm_embeddings/sp|O14756|H17B6_HUMAN.pt\nSaved embeddings for sp|O14757|CHK1_HUMAN to /kaggle/working/esm_embeddings/sp|O14757|CHK1_HUMAN.pt\nSaved embeddings for sp|O14763|TR10B_HUMAN to /kaggle/working/esm_embeddings/sp|O14763|TR10B_HUMAN.pt\nSaved embeddings for sp|O14788|TNF11_HUMAN to /kaggle/working/esm_embeddings/sp|O14788|TNF11_HUMAN.pt\nSaved embeddings for sp|O14804|TAAR5_HUMAN to /kaggle/working/esm_embeddings/sp|O14804|TAAR5_HUMAN.pt\nSaved embeddings for sp|O14813|PHX2A_HUMAN to /kaggle/working/esm_embeddings/sp|O14813|PHX2A_HUMAN.pt\nSaved embeddings for sp|O14843|FFAR3_HUMAN to /kaggle/working/esm_embeddings/sp|O14843|FFAR3_HUMAN.pt\nSaved embeddings for sp|O14907|TX1B3_HUMAN to /kaggle/working/esm_embeddings/sp|O14907|TX1B3_HUMAN.pt\nSaved embeddings for sp|O14908|GIPC1_HUMAN to /kaggle/working/esm_embeddings/sp|O14908|GIPC1_HUMAN.pt\nSaved embeddings for sp|O14910|LIN7A_HUMAN to /kaggle/working/esm_embeddings/sp|O14910|LIN7A_HUMAN.pt\nSaved embeddings for sp|O14925|TIM23_HUMAN to /kaggle/working/esm_embeddings/sp|O14925|TIM23_HUMAN.pt\nSaved embeddings for sp|O14926|FSCN2_HUMAN to /kaggle/working/esm_embeddings/sp|O14926|FSCN2_HUMAN.pt\nSaved embeddings for sp|O14933|UB2L6_HUMAN to /kaggle/working/esm_embeddings/sp|O14933|UB2L6_HUMAN.pt\nSaved embeddings for sp|O14939|PLD2_HUMAN to /kaggle/working/esm_embeddings/sp|O14939|PLD2_HUMAN.pt\nSaved embeddings for sp|O14949|QCR8_HUMAN to /kaggle/working/esm_embeddings/sp|O14949|QCR8_HUMAN.pt\nSaved embeddings for sp|O14958|CASQ2_HUMAN to /kaggle/working/esm_embeddings/sp|O14958|CASQ2_HUMAN.pt\nSaved embeddings for sp|O14960|LECT2_HUMAN to /kaggle/working/esm_embeddings/sp|O14960|LECT2_HUMAN.pt\nSaved embeddings for sp|O14967|CLGN_HUMAN to /kaggle/working/esm_embeddings/sp|O14967|CLGN_HUMAN.pt\nSaved embeddings for sp|O14975|S27A2_HUMAN to /kaggle/working/esm_embeddings/sp|O14975|S27A2_HUMAN.pt\nSaved embeddings for sp|O14979|HNRDL_HUMAN to /kaggle/working/esm_embeddings/sp|O14979|HNRDL_HUMAN.pt\nSaved embeddings for sp|O14994|SYN3_HUMAN to /kaggle/working/esm_embeddings/sp|O14994|SYN3_HUMAN.pt\nSaved embeddings for sp|O15067|PUR4_HUMAN to /kaggle/working/esm_embeddings/sp|O15067|PUR4_HUMAN.pt\nSaved embeddings for sp|O15078|CE290_HUMAN to /kaggle/working/esm_embeddings/sp|O15078|CE290_HUMAN.pt\nSaved embeddings for sp|O15111|IKKA_HUMAN to /kaggle/working/esm_embeddings/sp|O15111|IKKA_HUMAN.pt\nSaved embeddings for sp|O15116|LSM1_HUMAN to /kaggle/working/esm_embeddings/sp|O15116|LSM1_HUMAN.pt\nSaved embeddings for sp|O15119|TBX3_HUMAN to /kaggle/working/esm_embeddings/sp|O15119|TBX3_HUMAN.pt\nSaved embeddings for sp|O15120|PLCB_HUMAN to /kaggle/working/esm_embeddings/sp|O15120|PLCB_HUMAN.pt\nSaved embeddings for sp|O15127|SCAM2_HUMAN to /kaggle/working/esm_embeddings/sp|O15127|SCAM2_HUMAN.pt\nSaved embeddings for sp|O15156|ZBT7B_HUMAN to /kaggle/working/esm_embeddings/sp|O15156|ZBT7B_HUMAN.pt\nSaved embeddings for sp|O15162|PLS1_HUMAN to /kaggle/working/esm_embeddings/sp|O15162|PLS1_HUMAN.pt\nSaved embeddings for sp|O15169|AXIN1_HUMAN to /kaggle/working/esm_embeddings/sp|O15169|AXIN1_HUMAN.pt\nSaved embeddings for sp|O15230|LAMA5_HUMAN to /kaggle/working/esm_embeddings/sp|O15230|LAMA5_HUMAN.pt\nSaved embeddings for sp|O15232|MATN3_HUMAN to /kaggle/working/esm_embeddings/sp|O15232|MATN3_HUMAN.pt\nSaved embeddings for sp|O15245|S22A1_HUMAN to /kaggle/working/esm_embeddings/sp|O15245|S22A1_HUMAN.pt\nSaved embeddings for sp|O15247|CLIC2_HUMAN to /kaggle/working/esm_embeddings/sp|O15247|CLIC2_HUMAN.pt\nSaved embeddings for sp|O15259|NPHP1_HUMAN to /kaggle/working/esm_embeddings/sp|O15259|NPHP1_HUMAN.pt\nSaved embeddings for sp|O15260|SURF4_HUMAN to /kaggle/working/esm_embeddings/sp|O15260|SURF4_HUMAN.pt\nSaved embeddings for sp|O15263|DFB4A_HUMAN to /kaggle/working/esm_embeddings/sp|O15263|DFB4A_HUMAN.pt\nSaved embeddings for sp|O15265|ATX7_HUMAN to /kaggle/working/esm_embeddings/sp|O15265|ATX7_HUMAN.pt\nSaved embeddings for sp|O15266|SHOX_HUMAN to /kaggle/working/esm_embeddings/sp|O15266|SHOX_HUMAN.pt\nSaved embeddings for sp|O15269|SPTC1_HUMAN to /kaggle/working/esm_embeddings/sp|O15269|SPTC1_HUMAN.pt\nSaved embeddings for sp|O15297|PPM1D_HUMAN to /kaggle/working/esm_embeddings/sp|O15297|PPM1D_HUMAN.pt\nSaved embeddings for sp|O15318|RPC7_HUMAN to /kaggle/working/esm_embeddings/sp|O15318|RPC7_HUMAN.pt\nSaved embeddings for sp|O15370|SOX12_HUMAN to /kaggle/working/esm_embeddings/sp|O15370|SOX12_HUMAN.pt\nSaved embeddings for sp|O15389|SIGL5_HUMAN to /kaggle/working/esm_embeddings/sp|O15389|SIGL5_HUMAN.pt\nSaved embeddings for sp|O15399|NMDE4_HUMAN to /kaggle/working/esm_embeddings/sp|O15399|NMDE4_HUMAN.pt\nSaved embeddings for sp|O15400|STX7_HUMAN to /kaggle/working/esm_embeddings/sp|O15400|STX7_HUMAN.pt\nSaved embeddings for sp|O15446|RPA34_HUMAN to /kaggle/working/esm_embeddings/sp|O15446|RPA34_HUMAN.pt\nSaved embeddings for sp|O15484|CAN5_HUMAN to /kaggle/working/esm_embeddings/sp|O15484|CAN5_HUMAN.pt\nSaved embeddings for sp|O15488|GLYG2_HUMAN to /kaggle/working/esm_embeddings/sp|O15488|GLYG2_HUMAN.pt\nSaved embeddings for sp|O15511|ARPC5_HUMAN to /kaggle/working/esm_embeddings/sp|O15511|ARPC5_HUMAN.pt\nSaved embeddings for sp|O15520|FGF10_HUMAN to /kaggle/working/esm_embeddings/sp|O15520|FGF10_HUMAN.pt\nSaved embeddings for sp|O15533|TPSN_HUMAN to /kaggle/working/esm_embeddings/sp|O15533|TPSN_HUMAN.pt\nSaved embeddings for sp|O15540|FABP7_HUMAN to /kaggle/working/esm_embeddings/sp|O15540|FABP7_HUMAN.pt\nSaved embeddings for sp|O15541|R113A_HUMAN to /kaggle/working/esm_embeddings/sp|O15541|R113A_HUMAN.pt\nSaved embeddings for sp|O15551|CLD3_HUMAN to /kaggle/working/esm_embeddings/sp|O15551|CLD3_HUMAN.pt\nSaved embeddings for sp|O15554|KCNN4_HUMAN to /kaggle/working/esm_embeddings/sp|O15554|KCNN4_HUMAN.pt\nSaved embeddings for sp|O43143|DHX15_HUMAN to /kaggle/working/esm_embeddings/sp|O43143|DHX15_HUMAN.pt\nSaved embeddings for sp|O43155|FLRT2_HUMAN to /kaggle/working/esm_embeddings/sp|O43155|FLRT2_HUMAN.pt\nSaved embeddings for sp|O43166|SI1L1_HUMAN to /kaggle/working/esm_embeddings/sp|O43166|SI1L1_HUMAN.pt\nSaved embeddings for sp|O43172|PRP4_HUMAN to /kaggle/working/esm_embeddings/sp|O43172|PRP4_HUMAN.pt\nSaved embeddings for sp|O43181|NDUS4_HUMAN to /kaggle/working/esm_embeddings/sp|O43181|NDUS4_HUMAN.pt\nSaved embeddings for sp|O43196|MSH5_HUMAN to /kaggle/working/esm_embeddings/sp|O43196|MSH5_HUMAN.pt\nSaved embeddings for sp|O43237|DC1L2_HUMAN to /kaggle/working/esm_embeddings/sp|O43237|DC1L2_HUMAN.pt\nSaved embeddings for sp|O43264|ZW10_HUMAN to /kaggle/working/esm_embeddings/sp|O43264|ZW10_HUMAN.pt\nSaved embeddings for sp|O43294|TGFI1_HUMAN to /kaggle/working/esm_embeddings/sp|O43294|TGFI1_HUMAN.pt\nSaved embeddings for sp|O43310|CTIF_HUMAN to /kaggle/working/esm_embeddings/sp|O43310|CTIF_HUMAN.pt\nSaved embeddings for sp|O43323|DHH_HUMAN to /kaggle/working/esm_embeddings/sp|O43323|DHH_HUMAN.pt\nSaved embeddings for sp|O43395|PRPF3_HUMAN to /kaggle/working/esm_embeddings/sp|O43395|PRPF3_HUMAN.pt\nSaved embeddings for sp|O43439|MTG8R_HUMAN to /kaggle/working/esm_embeddings/sp|O43439|MTG8R_HUMAN.pt\nSaved embeddings for sp|O43464|HTRA2_HUMAN to /kaggle/working/esm_embeddings/sp|O43464|HTRA2_HUMAN.pt\nSaved embeddings for sp|O43474|KLF4_HUMAN to /kaggle/working/esm_embeddings/sp|O43474|KLF4_HUMAN.pt\nSaved embeddings for sp|O43521|B2L11_HUMAN to /kaggle/working/esm_embeddings/sp|O43521|B2L11_HUMAN.pt\nSaved embeddings for sp|O43525|KCNQ3_HUMAN to /kaggle/working/esm_embeddings/sp|O43525|KCNQ3_HUMAN.pt\nSaved embeddings for sp|O43526|KCNQ2_HUMAN to /kaggle/working/esm_embeddings/sp|O43526|KCNQ2_HUMAN.pt\nSaved embeddings for sp|O43529|CHSTA_HUMAN to /kaggle/working/esm_embeddings/sp|O43529|CHSTA_HUMAN.pt\nSaved embeddings for sp|O43543|XRCC2_HUMAN to /kaggle/working/esm_embeddings/sp|O43543|XRCC2_HUMAN.pt\nSaved embeddings for sp|O43548|TGM5_HUMAN to /kaggle/working/esm_embeddings/sp|O43548|TGM5_HUMAN.pt\nSaved embeddings for sp|O43556|SGCE_HUMAN to /kaggle/working/esm_embeddings/sp|O43556|SGCE_HUMAN.pt\nSaved embeddings for sp|O43566|RGS14_HUMAN to /kaggle/working/esm_embeddings/sp|O43566|RGS14_HUMAN.pt\nSaved embeddings for sp|O43581|SYT7_HUMAN to /kaggle/working/esm_embeddings/sp|O43581|SYT7_HUMAN.pt\nSaved embeddings for sp|O43593|HAIR_HUMAN to /kaggle/working/esm_embeddings/sp|O43593|HAIR_HUMAN.pt\nSaved embeddings for sp|O43598|DNPH1_HUMAN to /kaggle/working/esm_embeddings/sp|O43598|DNPH1_HUMAN.pt\nSaved embeddings for sp|O43603|GALR2_HUMAN to /kaggle/working/esm_embeddings/sp|O43603|GALR2_HUMAN.pt\nSaved embeddings for sp|O43609|SPY1_HUMAN to /kaggle/working/esm_embeddings/sp|O43609|SPY1_HUMAN.pt\nSaved embeddings for sp|O43715|TRIA1_HUMAN to /kaggle/working/esm_embeddings/sp|O43715|TRIA1_HUMAN.pt\nSaved embeddings for sp|O43719|HTSF1_HUMAN to /kaggle/working/esm_embeddings/sp|O43719|HTSF1_HUMAN.pt\nSaved embeddings for sp|O43761|SNG3_HUMAN to /kaggle/working/esm_embeddings/sp|O43761|SNG3_HUMAN.pt\nSaved embeddings for sp|O43763|TLX2_HUMAN to /kaggle/working/esm_embeddings/sp|O43763|TLX2_HUMAN.pt\nSaved embeddings for sp|O43808|PM34_HUMAN to /kaggle/working/esm_embeddings/sp|O43808|PM34_HUMAN.pt\nSaved embeddings for sp|O43818|U3IP2_HUMAN to /kaggle/working/esm_embeddings/sp|O43818|U3IP2_HUMAN.pt\nSaved embeddings for sp|O43823|AKAP8_HUMAN to /kaggle/working/esm_embeddings/sp|O43823|AKAP8_HUMAN.pt\nSaved embeddings for sp|O43825|B3GT2_HUMAN to /kaggle/working/esm_embeddings/sp|O43825|B3GT2_HUMAN.pt\nSaved embeddings for sp|O43826|G6PT1_HUMAN to /kaggle/working/esm_embeddings/sp|O43826|G6PT1_HUMAN.pt\nSaved embeddings for sp|O43827|ANGL7_HUMAN to /kaggle/working/esm_embeddings/sp|O43827|ANGL7_HUMAN.pt\nSaved embeddings for sp|O43854|EDIL3_HUMAN to /kaggle/working/esm_embeddings/sp|O43854|EDIL3_HUMAN.pt\nSaved embeddings for sp|O43865|SAHH2_HUMAN to /kaggle/working/esm_embeddings/sp|O43865|SAHH2_HUMAN.pt\nSaved embeddings for sp|O43866|CD5L_HUMAN to /kaggle/working/esm_embeddings/sp|O43866|CD5L_HUMAN.pt\nSaved embeddings for sp|O43868|S28A2_HUMAN to /kaggle/working/esm_embeddings/sp|O43868|S28A2_HUMAN.pt\nSaved embeddings for sp|O43897|TLL1_HUMAN to /kaggle/working/esm_embeddings/sp|O43897|TLL1_HUMAN.pt\nSaved embeddings for sp|O43903|GAS2_HUMAN to /kaggle/working/esm_embeddings/sp|O43903|GAS2_HUMAN.pt\nSaved embeddings for sp|O43913|ORC5_HUMAN to /kaggle/working/esm_embeddings/sp|O43913|ORC5_HUMAN.pt\nSaved embeddings for sp|O43914|TYOBP_HUMAN to /kaggle/working/esm_embeddings/sp|O43914|TYOBP_HUMAN.pt\nSaved embeddings for sp|O60235|TM11D_HUMAN to /kaggle/working/esm_embeddings/sp|O60235|TM11D_HUMAN.pt\nSaved embeddings for sp|O60264|SMCA5_HUMAN to /kaggle/working/esm_embeddings/sp|O60264|SMCA5_HUMAN.pt\nSaved embeddings for sp|O60266|ADCY3_HUMAN to /kaggle/working/esm_embeddings/sp|O60266|ADCY3_HUMAN.pt\nSaved embeddings for sp|O60284|ST18_HUMAN to /kaggle/working/esm_embeddings/sp|O60284|ST18_HUMAN.pt\nSaved embeddings for sp|O60307|MAST3_HUMAN to /kaggle/working/esm_embeddings/sp|O60307|MAST3_HUMAN.pt\nSaved embeddings for sp|O60315|ZEB2_HUMAN to /kaggle/working/esm_embeddings/sp|O60315|ZEB2_HUMAN.pt\nSaved embeddings for sp|O60381|HBP1_HUMAN to /kaggle/working/esm_embeddings/sp|O60381|HBP1_HUMAN.pt\nSaved embeddings for sp|O60393|NOBOX_HUMAN to /kaggle/working/esm_embeddings/sp|O60393|NOBOX_HUMAN.pt\nSaved embeddings for sp|O60449|LY75_HUMAN to /kaggle/working/esm_embeddings/sp|O60449|LY75_HUMAN.pt\nSaved embeddings for sp|O60469|DSCAM_HUMAN to /kaggle/working/esm_embeddings/sp|O60469|DSCAM_HUMAN.pt\nSaved embeddings for sp|O60481|ZIC3_HUMAN to /kaggle/working/esm_embeddings/sp|O60481|ZIC3_HUMAN.pt\nSaved embeddings for sp|O60502|OGA_HUMAN to /kaggle/working/esm_embeddings/sp|O60502|OGA_HUMAN.pt\nSaved embeddings for sp|O60519|CRBL2_HUMAN to /kaggle/working/esm_embeddings/sp|O60519|CRBL2_HUMAN.pt\nSaved embeddings for sp|O60548|FOXD2_HUMAN to /kaggle/working/esm_embeddings/sp|O60548|FOXD2_HUMAN.pt\nSaved embeddings for sp|O60568|PLOD3_HUMAN to /kaggle/working/esm_embeddings/sp|O60568|PLOD3_HUMAN.pt\nSaved embeddings for sp|O60635|TSN1_HUMAN to /kaggle/working/esm_embeddings/sp|O60635|TSN1_HUMAN.pt\nSaved embeddings for sp|O60636|TSN2_HUMAN to /kaggle/working/esm_embeddings/sp|O60636|TSN2_HUMAN.pt\nSaved embeddings for sp|O60667|FCMR_HUMAN to /kaggle/working/esm_embeddings/sp|O60667|FCMR_HUMAN.pt\nSaved embeddings for sp|O60678|ANM3_HUMAN to /kaggle/working/esm_embeddings/sp|O60678|ANM3_HUMAN.pt\nSaved embeddings for sp|O60682|MUSC_HUMAN to /kaggle/working/esm_embeddings/sp|O60682|MUSC_HUMAN.pt\nSaved embeddings for sp|O60687|SRPX2_HUMAN to /kaggle/working/esm_embeddings/sp|O60687|SRPX2_HUMAN.pt\nSaved embeddings for sp|O60706|ABCC9_HUMAN to /kaggle/working/esm_embeddings/sp|O60706|ABCC9_HUMAN.pt\nSaved embeddings for sp|O60729|CC14B_HUMAN to /kaggle/working/esm_embeddings/sp|O60729|CC14B_HUMAN.pt\nSaved embeddings for sp|O60741|HCN1_HUMAN to /kaggle/working/esm_embeddings/sp|O60741|HCN1_HUMAN.pt\nSaved embeddings for sp|O60759|CYTIP_HUMAN to /kaggle/working/esm_embeddings/sp|O60759|CYTIP_HUMAN.pt\nSaved embeddings for sp|O60784|TOM1_HUMAN to /kaggle/working/esm_embeddings/sp|O60784|TOM1_HUMAN.pt\nSaved embeddings for sp|O60814|H2B1K_HUMAN to /kaggle/working/esm_embeddings/sp|O60814|H2B1K_HUMAN.pt\nSaved embeddings for sp|O60831|PRAF2_HUMAN to /kaggle/working/esm_embeddings/sp|O60831|PRAF2_HUMAN.pt\nSaved embeddings for sp|O60879|DIAP2_HUMAN to /kaggle/working/esm_embeddings/sp|O60879|DIAP2_HUMAN.pt\nSaved embeddings for sp|O60882|MMP20_HUMAN to /kaggle/working/esm_embeddings/sp|O60882|MMP20_HUMAN.pt\nSaved embeddings for sp|O60884|DNJA2_HUMAN to /kaggle/working/esm_embeddings/sp|O60884|DNJA2_HUMAN.pt\nSaved embeddings for sp|O60909|B4GT2_HUMAN to /kaggle/working/esm_embeddings/sp|O60909|B4GT2_HUMAN.pt\nSaved embeddings for sp|O60921|HUS1_HUMAN to /kaggle/working/esm_embeddings/sp|O60921|HUS1_HUMAN.pt\nSaved embeddings for sp|O60930|RNH1_HUMAN to /kaggle/working/esm_embeddings/sp|O60930|RNH1_HUMAN.pt\nSaved embeddings for sp|O60938|KERA_HUMAN to /kaggle/working/esm_embeddings/sp|O60938|KERA_HUMAN.pt\nSaved embeddings for sp|O60939|SCN2B_HUMAN to /kaggle/working/esm_embeddings/sp|O60939|SCN2B_HUMAN.pt\nSaved embeddings for sp|O60941|DTNB_HUMAN to /kaggle/working/esm_embeddings/sp|O60941|DTNB_HUMAN.pt\nSaved embeddings for sp|O60942|MCE1_HUMAN to /kaggle/working/esm_embeddings/sp|O60942|MCE1_HUMAN.pt\nSaved embeddings for sp|O75019|LIRA1_HUMAN to /kaggle/working/esm_embeddings/sp|O75019|LIRA1_HUMAN.pt\nSaved embeddings for sp|O75022|LIRB3_HUMAN to /kaggle/working/esm_embeddings/sp|O75022|LIRB3_HUMAN.pt\nSaved embeddings for sp|O75072|FKTN_HUMAN to /kaggle/working/esm_embeddings/sp|O75072|FKTN_HUMAN.pt\nSaved embeddings for sp|O75077|ADA23_HUMAN to /kaggle/working/esm_embeddings/sp|O75077|ADA23_HUMAN.pt\nSaved embeddings for sp|O75132|ZBED4_HUMAN to /kaggle/working/esm_embeddings/sp|O75132|ZBED4_HUMAN.pt\nSaved embeddings for sp|O75151|PHF2_HUMAN to /kaggle/working/esm_embeddings/sp|O75151|PHF2_HUMAN.pt\nSaved embeddings for sp|O75159|SOCS5_HUMAN to /kaggle/working/esm_embeddings/sp|O75159|SOCS5_HUMAN.pt\nSaved embeddings for sp|O75175|CNOT3_HUMAN to /kaggle/working/esm_embeddings/sp|O75175|CNOT3_HUMAN.pt\nSaved embeddings for sp|O75177|CREST_HUMAN to /kaggle/working/esm_embeddings/sp|O75177|CREST_HUMAN.pt\nSaved embeddings for sp|O75190|DNJB6_HUMAN to /kaggle/working/esm_embeddings/sp|O75190|DNJB6_HUMAN.pt\nSaved embeddings for sp|O75191|XYLB_HUMAN to /kaggle/working/esm_embeddings/sp|O75191|XYLB_HUMAN.pt\nSaved embeddings for sp|O75309|CAD16_HUMAN to /kaggle/working/esm_embeddings/sp|O75309|CAD16_HUMAN.pt\nSaved embeddings for sp|O75319|DUS11_HUMAN to /kaggle/working/esm_embeddings/sp|O75319|DUS11_HUMAN.pt\nSaved embeddings for sp|O75334|LIPA2_HUMAN to /kaggle/working/esm_embeddings/sp|O75334|LIPA2_HUMAN.pt\nSaved embeddings for sp|O75339|CILP1_HUMAN to /kaggle/working/esm_embeddings/sp|O75339|CILP1_HUMAN.pt\nSaved embeddings for sp|O75344|FKBP6_HUMAN to /kaggle/working/esm_embeddings/sp|O75344|FKBP6_HUMAN.pt\nSaved embeddings for sp|O75365|TP4A3_HUMAN to /kaggle/working/esm_embeddings/sp|O75365|TP4A3_HUMAN.pt\nSaved embeddings for sp|O75367|H2AY_HUMAN to /kaggle/working/esm_embeddings/sp|O75367|H2AY_HUMAN.pt\nSaved embeddings for sp|O75369|FLNB_HUMAN to /kaggle/working/esm_embeddings/sp|O75369|FLNB_HUMAN.pt\nSaved embeddings for sp|O75376|NCOR1_HUMAN to /kaggle/working/esm_embeddings/sp|O75376|NCOR1_HUMAN.pt\nSaved embeddings for sp|O75379|VAMP4_HUMAN to /kaggle/working/esm_embeddings/sp|O75379|VAMP4_HUMAN.pt\nSaved embeddings for sp|O75390|CISY_HUMAN to /kaggle/working/esm_embeddings/sp|O75390|CISY_HUMAN.pt\nSaved embeddings for sp|O75396|SC22B_HUMAN to /kaggle/working/esm_embeddings/sp|O75396|SC22B_HUMAN.pt\nSaved embeddings for sp|O75438|NDUB1_HUMAN to /kaggle/working/esm_embeddings/sp|O75438|NDUB1_HUMAN.pt\nSaved embeddings for sp|O75443|TECTA_HUMAN to /kaggle/working/esm_embeddings/sp|O75443|TECTA_HUMAN.pt\nSaved embeddings for sp|O75449|KTNA1_HUMAN to /kaggle/working/esm_embeddings/sp|O75449|KTNA1_HUMAN.pt\nSaved embeddings for sp|O75469|NR1I2_HUMAN to /kaggle/working/esm_embeddings/sp|O75469|NR1I2_HUMAN.pt\nSaved embeddings for sp|O75475|PSIP1_HUMAN to /kaggle/working/esm_embeddings/sp|O75475|PSIP1_HUMAN.pt\nSaved embeddings for sp|O75486|SUPT3_HUMAN to /kaggle/working/esm_embeddings/sp|O75486|SUPT3_HUMAN.pt\nSaved embeddings for sp|O75503|CLN5_HUMAN to /kaggle/working/esm_embeddings/sp|O75503|CLN5_HUMAN.pt\nSaved embeddings for sp|O75554|WBP4_HUMAN to /kaggle/working/esm_embeddings/sp|O75554|WBP4_HUMAN.pt\nSaved embeddings for sp|O75558|STX11_HUMAN to /kaggle/working/esm_embeddings/sp|O75558|STX11_HUMAN.pt\nSaved embeddings for sp|O75564|JERKY_HUMAN to /kaggle/working/esm_embeddings/sp|O75564|JERKY_HUMAN.pt\nSaved embeddings for sp|O75594|PGRP1_HUMAN to /kaggle/working/esm_embeddings/sp|O75594|PGRP1_HUMAN.pt\nSaved embeddings for sp|O75610|LFTY1_HUMAN to /kaggle/working/esm_embeddings/sp|O75610|LFTY1_HUMAN.pt\nSaved embeddings for sp|O75618|DEDD_HUMAN to /kaggle/working/esm_embeddings/sp|O75618|DEDD_HUMAN.pt\nSaved embeddings for sp|O75629|CREG1_HUMAN to /kaggle/working/esm_embeddings/sp|O75629|CREG1_HUMAN.pt\nSaved embeddings for sp|O75638|CTAG2_HUMAN to /kaggle/working/esm_embeddings/sp|O75638|CTAG2_HUMAN.pt\nSaved embeddings for sp|O75648|MTU1_HUMAN to /kaggle/working/esm_embeddings/sp|O75648|MTU1_HUMAN.pt\nSaved embeddings for sp|O75674|TM1L1_HUMAN to /kaggle/working/esm_embeddings/sp|O75674|TM1L1_HUMAN.pt\nSaved embeddings for sp|O75679|RFPL3_HUMAN to /kaggle/working/esm_embeddings/sp|O75679|RFPL3_HUMAN.pt\nSaved embeddings for sp|O75683|SURF6_HUMAN to /kaggle/working/esm_embeddings/sp|O75683|SURF6_HUMAN.pt\nSaved embeddings for sp|O75752|B3GL1_HUMAN to /kaggle/working/esm_embeddings/sp|O75752|B3GL1_HUMAN.pt\nSaved embeddings for sp|O75762|TRPA1_HUMAN to /kaggle/working/esm_embeddings/sp|O75762|TRPA1_HUMAN.pt\nSaved embeddings for sp|O75781|PALM_HUMAN to /kaggle/working/esm_embeddings/sp|O75781|PALM_HUMAN.pt\nSaved embeddings for sp|O75807|PR15A_HUMAN to /kaggle/working/esm_embeddings/sp|O75807|PR15A_HUMAN.pt\nSaved embeddings for sp|O75815|BCAR3_HUMAN to /kaggle/working/esm_embeddings/sp|O75815|BCAR3_HUMAN.pt\nSaved embeddings for sp|O75821|EIF3G_HUMAN to /kaggle/working/esm_embeddings/sp|O75821|EIF3G_HUMAN.pt\nSaved embeddings for sp|O75828|CBR3_HUMAN to /kaggle/working/esm_embeddings/sp|O75828|CBR3_HUMAN.pt\nSaved embeddings for sp|O75838|CIB2_HUMAN to /kaggle/working/esm_embeddings/sp|O75838|CIB2_HUMAN.pt\nSaved embeddings for sp|O75864|PPR37_HUMAN to /kaggle/working/esm_embeddings/sp|O75864|PPR37_HUMAN.pt\nSaved embeddings for sp|O75879|GATB_HUMAN to /kaggle/working/esm_embeddings/sp|O75879|GATB_HUMAN.pt\nSaved embeddings for sp|O75882|ATRN_HUMAN to /kaggle/working/esm_embeddings/sp|O75882|ATRN_HUMAN.pt\nSaved embeddings for sp|O75884|RBBP9_HUMAN to /kaggle/working/esm_embeddings/sp|O75884|RBBP9_HUMAN.pt\nSaved embeddings for sp|O75897|ST1C4_HUMAN to /kaggle/working/esm_embeddings/sp|O75897|ST1C4_HUMAN.pt\nSaved embeddings for sp|O75928|PIAS2_HUMAN to /kaggle/working/esm_embeddings/sp|O75928|PIAS2_HUMAN.pt\nSaved embeddings for sp|O75935|DCTN3_HUMAN to /kaggle/working/esm_embeddings/sp|O75935|DCTN3_HUMAN.pt\nSaved embeddings for sp|O75952|CABYR_HUMAN to /kaggle/working/esm_embeddings/sp|O75952|CABYR_HUMAN.pt\nSaved embeddings for sp|O75956|CDKA2_HUMAN to /kaggle/working/esm_embeddings/sp|O75956|CDKA2_HUMAN.pt\nSaved embeddings for sp|O75964|ATP5L_HUMAN to /kaggle/working/esm_embeddings/sp|O75964|ATP5L_HUMAN.pt\nSaved embeddings for sp|O75969|AKAP3_HUMAN to /kaggle/working/esm_embeddings/sp|O75969|AKAP3_HUMAN.pt\nSaved embeddings for sp|O76027|ANXA9_HUMAN to /kaggle/working/esm_embeddings/sp|O76027|ANXA9_HUMAN.pt\nSaved embeddings for sp|O76039|CDKL5_HUMAN to /kaggle/working/esm_embeddings/sp|O76039|CDKL5_HUMAN.pt\nSaved embeddings for sp|O76074|PDE5A_HUMAN to /kaggle/working/esm_embeddings/sp|O76074|PDE5A_HUMAN.pt\nSaved embeddings for sp|O76075|DFFB_HUMAN to /kaggle/working/esm_embeddings/sp|O76075|DFFB_HUMAN.pt\nSaved embeddings for sp|O76093|FGF18_HUMAN to /kaggle/working/esm_embeddings/sp|O76093|FGF18_HUMAN.pt\nSaved embeddings for sp|O77932|DXO_HUMAN to /kaggle/working/esm_embeddings/sp|O77932|DXO_HUMAN.pt\nSaved embeddings for sp|O94762|RECQ5_HUMAN to /kaggle/working/esm_embeddings/sp|O94762|RECQ5_HUMAN.pt\nSaved embeddings for sp|O94768|ST17B_HUMAN to /kaggle/working/esm_embeddings/sp|O94768|ST17B_HUMAN.pt\nSaved embeddings for sp|O94805|ACL6B_HUMAN to /kaggle/working/esm_embeddings/sp|O94805|ACL6B_HUMAN.pt\nSaved embeddings for sp|O94808|GFPT2_HUMAN to /kaggle/working/esm_embeddings/sp|O94808|GFPT2_HUMAN.pt\nSaved embeddings for sp|O94810|RGS11_HUMAN to /kaggle/working/esm_embeddings/sp|O94810|RGS11_HUMAN.pt\nSaved embeddings for sp|O94818|NOL4_HUMAN to /kaggle/working/esm_embeddings/sp|O94818|NOL4_HUMAN.pt\nSaved embeddings for sp|O94876|TMCC1_HUMAN to /kaggle/working/esm_embeddings/sp|O94876|TMCC1_HUMAN.pt\nSaved embeddings for sp|O94889|KLH18_HUMAN to /kaggle/working/esm_embeddings/sp|O94889|KLH18_HUMAN.pt\nSaved embeddings for sp|O94898|LRIG2_HUMAN to /kaggle/working/esm_embeddings/sp|O94898|LRIG2_HUMAN.pt\nSaved embeddings for sp|O94901|SUN1_HUMAN to /kaggle/working/esm_embeddings/sp|O94901|SUN1_HUMAN.pt\nSaved embeddings for sp|O94923|GLCE_HUMAN to /kaggle/working/esm_embeddings/sp|O94923|GLCE_HUMAN.pt\nSaved embeddings for sp|O94964|MTCL2_HUMAN to /kaggle/working/esm_embeddings/sp|O94964|MTCL2_HUMAN.pt\nSaved embeddings for sp|O94983|CMTA2_HUMAN to /kaggle/working/esm_embeddings/sp|O94983|CMTA2_HUMAN.pt\nSaved embeddings for sp|O94985|CSTN1_HUMAN to /kaggle/working/esm_embeddings/sp|O94985|CSTN1_HUMAN.pt\nSaved embeddings for sp|O94993|SOX30_HUMAN to /kaggle/working/esm_embeddings/sp|O94993|SOX30_HUMAN.pt\nSaved embeddings for sp|O95047|OR2A4_HUMAN to /kaggle/working/esm_embeddings/sp|O95047|OR2A4_HUMAN.pt\nSaved embeddings for sp|O95049|ZO3_HUMAN to /kaggle/working/esm_embeddings/sp|O95049|ZO3_HUMAN.pt\nSaved embeddings for sp|O95125|ZN202_HUMAN to /kaggle/working/esm_embeddings/sp|O95125|ZN202_HUMAN.pt\nSaved embeddings for sp|O95139|NDUB6_HUMAN to /kaggle/working/esm_embeddings/sp|O95139|NDUB6_HUMAN.pt\nSaved embeddings for sp|O95153|RIMB1_HUMAN to /kaggle/working/esm_embeddings/sp|O95153|RIMB1_HUMAN.pt\nSaved embeddings for sp|O95154|ARK73_HUMAN to /kaggle/working/esm_embeddings/sp|O95154|ARK73_HUMAN.pt\nSaved embeddings for sp|O95155|UBE4B_HUMAN to /kaggle/working/esm_embeddings/sp|O95155|UBE4B_HUMAN.pt\nSaved embeddings for sp|O95169|NDUB8_HUMAN to /kaggle/working/esm_embeddings/sp|O95169|NDUB8_HUMAN.pt\nSaved embeddings for sp|O95208|EPN2_HUMAN to /kaggle/working/esm_embeddings/sp|O95208|EPN2_HUMAN.pt\nSaved embeddings for sp|O95237|LRAT_HUMAN to /kaggle/working/esm_embeddings/sp|O95237|LRAT_HUMAN.pt\nSaved embeddings for sp|O95248|MTMR5_HUMAN to /kaggle/working/esm_embeddings/sp|O95248|MTMR5_HUMAN.pt\nSaved embeddings for sp|O95260|ATE1_HUMAN to /kaggle/working/esm_embeddings/sp|O95260|ATE1_HUMAN.pt\nSaved embeddings for sp|O95274|LYPD3_HUMAN to /kaggle/working/esm_embeddings/sp|O95274|LYPD3_HUMAN.pt\nSaved embeddings for sp|O95294|RASL1_HUMAN to /kaggle/working/esm_embeddings/sp|O95294|RASL1_HUMAN.pt\nSaved embeddings for sp|O95298|NDUC2_HUMAN to /kaggle/working/esm_embeddings/sp|O95298|NDUC2_HUMAN.pt\nSaved embeddings for sp|O95342|ABCBB_HUMAN to /kaggle/working/esm_embeddings/sp|O95342|ABCBB_HUMAN.pt\nSaved embeddings for sp|O95343|SIX3_HUMAN to /kaggle/working/esm_embeddings/sp|O95343|SIX3_HUMAN.pt\nSaved embeddings for sp|O95352|ATG7_HUMAN to /kaggle/working/esm_embeddings/sp|O95352|ATG7_HUMAN.pt\nSaved embeddings for sp|O95361|TRI16_HUMAN to /kaggle/working/esm_embeddings/sp|O95361|TRI16_HUMAN.pt\nSaved embeddings for sp|O95373|IPO7_HUMAN to /kaggle/working/esm_embeddings/sp|O95373|IPO7_HUMAN.pt\nSaved embeddings for sp|O95393|BMP10_HUMAN to /kaggle/working/esm_embeddings/sp|O95393|BMP10_HUMAN.pt\nSaved embeddings for sp|O95394|AGM1_HUMAN to /kaggle/working/esm_embeddings/sp|O95394|AGM1_HUMAN.pt\nSaved embeddings for sp|O95415|BRI3_HUMAN to /kaggle/working/esm_embeddings/sp|O95415|BRI3_HUMAN.pt\nSaved embeddings for sp|O95427|PIGN_HUMAN to /kaggle/working/esm_embeddings/sp|O95427|PIGN_HUMAN.pt\nSaved embeddings for sp|O95429|BAG4_HUMAN to /kaggle/working/esm_embeddings/sp|O95429|BAG4_HUMAN.pt\nSaved embeddings for sp|O95447|LCA5L_HUMAN to /kaggle/working/esm_embeddings/sp|O95447|LCA5L_HUMAN.pt\nSaved embeddings for sp|O95466|FMNL1_HUMAN to /kaggle/working/esm_embeddings/sp|O95466|FMNL1_HUMAN.pt\nSaved embeddings for sp|O95470|SGPL1_HUMAN to /kaggle/working/esm_embeddings/sp|O95470|SGPL1_HUMAN.pt\nSaved embeddings for sp|O95479|G6PE_HUMAN to /kaggle/working/esm_embeddings/sp|O95479|G6PE_HUMAN.pt\nSaved embeddings for sp|O95497|VNN1_HUMAN to /kaggle/working/esm_embeddings/sp|O95497|VNN1_HUMAN.pt\nSaved embeddings for sp|O95528|GTR10_HUMAN to /kaggle/working/esm_embeddings/sp|O95528|GTR10_HUMAN.pt\nSaved embeddings for sp|O95544|NADK_HUMAN to /kaggle/working/esm_embeddings/sp|O95544|NADK_HUMAN.pt\nSaved embeddings for sp|O95571|ETHE1_HUMAN to /kaggle/working/esm_embeddings/sp|O95571|ETHE1_HUMAN.pt\nSaved embeddings for sp|O95622|ADCY5_HUMAN to /kaggle/working/esm_embeddings/sp|O95622|ADCY5_HUMAN.pt\nSaved embeddings for sp|O95630|STABP_HUMAN to /kaggle/working/esm_embeddings/sp|O95630|STABP_HUMAN.pt\nSaved embeddings for sp|O95670|VATG2_HUMAN to /kaggle/working/esm_embeddings/sp|O95670|VATG2_HUMAN.pt\nSaved embeddings for sp|O95674|CDS2_HUMAN to /kaggle/working/esm_embeddings/sp|O95674|CDS2_HUMAN.pt\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2109521204.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Generate embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Extract embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/esm/modeling_esm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         )\n\u001b[0;32m--> 963\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/esm/modeling_esm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mpast_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    730\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/esm/modeling_esm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/esm/modeling_esm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    563\u001b[0m     ):\n\u001b[1;32m    564\u001b[0m         \u001b[0mhidden_states_ln\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mhidden_states_ln\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/esm/modeling_esm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;31m# Apply the attention mask is (precomputed for all layers in EsmModel forward() function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacity of 15.89 GiB of which 743.12 MiB is free. Process 4822 has 15.16 GiB memory in use. Of the allocated memory 14.50 GiB is allocated by PyTorch, and 379.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacity of 15.89 GiB of which 743.12 MiB is free. Process 4822 has 15.16 GiB memory in use. Of the allocated memory 14.50 GiB is allocated by PyTorch, and 379.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"from zipfile import ZipFile\n\ndirName = '/kaggle/working'\nzipName = 'fair-esm-suman.zip'\n\n# Create a ZipFile Object\nwith ZipFile(zipName, 'w') as zipObj:\n    # Iterate over all the files in directory\n    for folderName, subfolders, filenames in os.walk(dirName):\n        for filename in filenames:\n            if (filename != zipName):\n                # create complete filepath of file in directory\n                filePath = os.path.join(folderName, filename)\n                # Add file to zip\n                zipObj.write(filePath)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install fair-esm --no-index --find-links=/kaggle/input/suman-fair-esm/kaggle/working/fair_esm-2.0.0-py3-none-any.whl","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python --version","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import esm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_embeddings_from_fasta_v0_1_0_manual(fasta_file, output_dir):\n    \"\"\"\n    Generates and saves protein embeddings from a FASTA file for fair-esm==0.1.0.\n    \"\"\"\n    # Load the model and alphabet (adjust model name if needed for v0.1.0)\n    model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n    model = model.eval()\n    if torch.cuda.is_available():\n        model = model.cuda()\n    \n    # Use the batch converter\n    batch_converter = alphabet.get_batch_converter()\n    \n    # Manually read sequences from the FASTA file\n    data = []\n    with open(fasta_file, \"r\") as f:\n        current_label = None\n        current_seq = []\n        for line in f:\n            line = line.strip()\n            if line.startswith(\">\"):\n                if current_label and current_seq:\n                    data.append((current_label, \"\".join(current_seq)))\n                current_label = line[1:]\n                current_seq = []\n            else:\n                current_seq.append(line)\n        if current_label and current_seq:\n            data.append((current_label, \"\".join(current_seq)))\n\n    os.makedirs(output_dir, exist_ok=True)\n    \n    # Convert data into a batch of tokens\n    batch_labels, batch_strs, batch_tokens = batch_converter(data)\n    \n    # Move tokens to device\n    batch_tokens = batch_tokens.to(next(model.parameters()).device)\n\n    with torch.no_grad():\n        # Get model embeddings (using 'representations' key for v0.1.0)\n        results = model(batch_tokens, repr_layers=[model.num_layers])\n        sequence_representations = results[\"representations\"][model.num_layers]\n\n        # Iterate and save embeddings\n        for i, label in enumerate(batch_labels):\n            filename = os.path.join(output_dir, f\"{label.replace('/', '_').replace('|', '_')}.pt\")\n            \n            # Average over sequence length, excluding BOS token\n            seq_len = len(batch_strs[i])\n            mean_embedding = sequence_representations[i, 1:seq_len + 1].mean(0).cpu().numpy()\n            \n            # Save embedding\n            torch.save({\"mean_representations\": mean_embedding}, filename)\n            print(f\"Saved embedding for {label} to {filename}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generate_embeddings_from_fasta_v0_1_0_manual(\"/kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta\" \\\n                               , \"output_embeddings_dir/\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}