{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":116062,"databundleVersionId":14084779,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install duckdb --no-index --find-links=/kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/duck_pkg\n!pip install polars --no-index --find-links=/kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg\n!pip install biopython\n#!pip install fair-esm --no-index --find-links=/kaggle/input/suman-fair-esm/kaggle/working/fair_esm-2.0.0-py3-none-any.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T04:44:48.549079Z","iopub.execute_input":"2025-11-27T04:44:48.549430Z","iopub.status.idle":"2025-11-27T04:45:01.116938Z","shell.execute_reply.started":"2025-11-27T04:44:48.549403Z","shell.execute_reply":"2025-11-27T04:45:01.116073Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/duck_pkg\nRequirement already satisfied: duckdb in /usr/local/lib/python3.11/dist-packages (1.3.2)\nLooking in links: /kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg\nRequirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (1.25.0)\nCollecting biopython\n  Downloading biopython-1.86-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->biopython) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->biopython) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->biopython) (2024.2.0)\nDownloading biopython-1.86-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: biopython\nSuccessfully installed biopython-1.86\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport random\nimport pprint\nimport os\nimport duckdb as dd\nimport polars as pl\nfrom Bio import SeqIO\n\nimport transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T04:45:28.605364Z","iopub.execute_input":"2025-11-27T04:45:28.605706Z","iopub.status.idle":"2025-11-27T04:45:35.535727Z","shell.execute_reply.started":"2025-11-27T04:45:28.605673Z","shell.execute_reply":"2025-11-27T04:45:35.534871Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"## Run this twice, first time, it will show error\nfrom transformers import AutoTokenizer, EsmModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T04:46:52.083413Z","iopub.execute_input":"2025-11-27T04:46:52.084644Z","iopub.status.idle":"2025-11-27T04:46:52.088180Z","shell.execute_reply.started":"2025-11-27T04:46:52.084606Z","shell.execute_reply":"2025-11-27T04:46:52.087403Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model_to_use = 'facebook/esm2_t6_8M_UR50D'\nfasta_file_path = '/kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta'\noutput_embed_dir = \"/kaggle/working/esm_embeddings\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T04:56:26.719910Z","iopub.execute_input":"2025-11-27T04:56:26.720587Z","iopub.status.idle":"2025-11-27T04:56:26.724161Z","shell.execute_reply.started":"2025-11-27T04:56:26.720561Z","shell.execute_reply":"2025-11-27T04:56:26.723545Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_to_use)\nmodel = EsmModel.from_pretrained(model_to_use)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.to(device)\nmodel.eval()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs(output_dir, exist_ok=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sequences = SeqIO.parse(fasta_file_path, \"fasta\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_sequences_list = list(sequences)\nlen(train_sequences_list)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"last_record = train_sequences_list[-1]  # using Python's list tricks\nprint(last_record.id)\nprint(repr(last_record.seq))\nprint(len(last_record))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_sequences_list[1001:1801])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for record in train_sequences_list[1001:1801]:\n    seq_id = record.id\n    sequence = str(record.seq)\n\n    # Tokenize the sequence\n    # The tokenizer adds special tokens (CLS and SEP) automatically\n    inputs = tokenizer(sequence, return_tensors='pt', padding=True, truncation=True)\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n\n    # Generate embeddings\n    with torch.no_grad():\n        output = model(**inputs)\n\n    # Extract embeddings\n    # We usually take the last hidden states\n    embeddings = output.last_hidden_state # Shape: (batch_size, sequence_length, hidden_size)\n\n    # To get a single fixed-size embedding for the whole protein (mean pooling), \n    # you can average over the sequence length dimension (excluding CLS/SEP if desired, though often included for simplicity)\n    # Here we average over all tokens in the sequence.\n    # Alternatively, you can use the representation of the CLS token\n    # sequence_level_embedding = output.pooler_output # This only works for certain model configurations\n    \n    # Mean pooling as an alternative to pooler_output\n    # Start from index 1 and end at index -1 to ignore CLS and SEP tokens if they exist, \n    # but the standard practice with ESM is often to include all or use the representation from a specific layer\n    # For simplicity, we can do mean pooling across the sequence dimension for now:\n    sequence_embeddings = embeddings.mean(dim=1).squeeze().cpu().numpy() # Shape: (hidden_size,)\n\n    # Save the embeddings\n    output_path = os.path.join(output_dir, f\"{seq_id}.pt\")\n    torch.save({'embeddings': sequence_embeddings}, output_path) # Save as a dictionary\n    print(f\"Saved embeddings for {seq_id} to {output_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del inputs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del output\ndel embeddings\ndel sequence_embeddings","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm.notebook import tqdm # Use tqdm for a progress bar in Kaggle/Jupyter\n\ndef generate_embeddings_optimized(fasta_file, output_dir, model_name='facebook/esm2_t12_35M_UR50D', batch_size=4):\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    \n    # Load model in float16 for memory efficiency (Requires modern GPU/hardware)\n    model = EsmModel.from_pretrained(model_name, torch_dtype=torch.float16) \n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Read all sequences into a list first to prepare for batching\n    sequences = list(SeqIO.parse(fasta_file, \"fasta\"))\n    print(f\"Total sequences to process: {len(sequences)}\")\n\n    for i in tqdm(range(0, len(sequences), batch_size)):\n        batch = sequences[i:i+batch_size]\n        seq_ids = [record.id for record in batch]\n        seqs = [str(record.seq) for record in batch]\n\n        # Tokenize the batch\n        inputs = tokenizer(seqs, return_tensors='pt', padding=True, truncation=True, max_length=1022)\n        inputs = {k: v.to(device) for k, v in inputs.items()}\n\n        with torch.no_grad():\n            outputs = model(**inputs)\n\n        # Extract and save embeddings individually to manage memory\n        for j, seq_id in enumerate(seq_ids):\n            # Mean pooling for sequence-level embedding\n            embedding = outputs.last_hidden_state[j].mean(dim=0).cpu().numpy()\n            output_path = os.path.join(output_dir, f\"{seq_id}.pt\")\n            torch.save({'embeddings': embedding}, output_path)\n\n        # Explicitly clear input and output tensors to free VRAM immediately\n        del inputs, outputs, batch\n        torch.cuda.empty_cache()\n\n    print(\"Embedding generation complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T04:57:44.291348Z","iopub.execute_input":"2025-11-27T04:57:44.291881Z","iopub.status.idle":"2025-11-27T04:57:44.299547Z","shell.execute_reply.started":"2025-11-27T04:57:44.291854Z","shell.execute_reply":"2025-11-27T04:57:44.298970Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Example usage with a smaller, memory-efficient model:\ngenerate_embeddings_optimized(fasta_file_path, output_embed_dir, model_to_use, 8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T04:57:49.240230Z","iopub.execute_input":"2025-11-27T04:57:49.240758Z","iopub.status.idle":"2025-11-27T05:17:05.068222Z","shell.execute_reply.started":"2025-11-27T04:57:49.240733Z","shell.execute_reply":"2025-11-27T05:17:05.067685Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/95.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae43eba487694a7c9cdf9610f6f73d1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/93.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac746d8981e540289a9ba0c69e55192b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ba777ab994345fba8dbbc663f15671a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/775 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95ce55b4b7b0453c8b793414a08c062b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/31.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"470eb5c40ef94012bc6459961170dd4b"}},"metadata":{}},{"name":"stderr","text":"Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Total sequences to process: 82404\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10301 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58b4845d40ff4a8b82808f11289edcf0"}},"metadata":{}},{"name":"stdout","text":"Embedding generation complete.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from zipfile import ZipFile\n\ndirName = '/kaggle/working'\nzipName = 'esm2_t36_3B_UR50D_embeds_suman.zip'\n\n# Create a ZipFile Object\nwith ZipFile(zipName, 'w') as zipObj:\n    # Iterate over all the files in directory\n    for folderName, subfolders, filenames in os.walk(dirName):\n        for filename in filenames:\n            if (filename != zipName):\n                # create complete filepath of file in directory\n                filePath = os.path.join(folderName, filename)\n                # Add file to zip\n                zipObj.write(filePath)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:20:45.295169Z","iopub.execute_input":"2025-11-27T05:20:45.295849Z","iopub.status.idle":"2025-11-27T05:20:50.475758Z","shell.execute_reply.started":"2025-11-27T05:20:45.295814Z","shell.execute_reply":"2025-11-27T05:20:50.475067Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def embeddings_to_dataframe(directory_path):\n    \"\"\"Loads embeddings and organizes them into a Pandas DataFrame.\"\"\"\n    data_list = []\n    for filename in tqdm(os.listdir(directory_path)):\n        if filename.endswith(\".pt\"):\n            file_path = os.path.join(directory_path, filename)\n            data = torch.load(file_path, weights_only=False)\n            seq_id = os.path.splitext(filename)[0]\n            \n            # The embedding data itself is in 'embeddings'\n            embedding = data['embeddings'] \n            \n            # Create a row for the DataFrame\n            row = {'Sequence_ID': seq_id, 'Embedding': embedding}\n            data_list.append(row)\n            \n    #df = pd.DataFrame(data_list)\n    df = pl.DataFrame(data_list)\n    print(f\"DataFrame created with {len(df)} entries.\")\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:26:32.563582Z","iopub.execute_input":"2025-11-27T05:26:32.563922Z","iopub.status.idle":"2025-11-27T05:26:32.572742Z","shell.execute_reply.started":"2025-11-27T05:26:32.563898Z","shell.execute_reply":"2025-11-27T05:26:32.571975Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Example usage:\nembeddings_df = embeddings_to_dataframe(\"/kaggle/working/esm_embeddings\")\nprint(embeddings_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:26:35.898647Z","iopub.execute_input":"2025-11-27T05:26:35.899517Z","iopub.status.idle":"2025-11-27T05:26:49.933728Z","shell.execute_reply.started":"2025-11-27T05:26:35.899484Z","shell.execute_reply":"2025-11-27T05:26:49.933085Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/82404 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95f08f87778845fbaa7bb1cf24300066"}},"metadata":{}},{"name":"stdout","text":"DataFrame created with 82404 entries.\nshape: (5, 2)\n┌──────────────────────────┬─────────────────────────────────┐\n│ Sequence_ID              ┆ Embedding                       │\n│ ---                      ┆ ---                             │\n│ str                      ┆ object                          │\n╞══════════════════════════╪═════════════════════════════════╡\n│ sp|D3ZHV2|MACF1_RAT      ┆ [-1.1731e-01 -1.2988e-01  3.58… │\n│ sp|Q6NLB0|GSTL1_ARATH    ┆ [-1.7563e-02 -1.1700e-01  1.25… │\n│ sp|P82233|BR1A_RANTE     ┆ [-4.3030e-02 -1.8921e-02  2.26… │\n│ sp|Q6P5F6|S39AA_MOUSE    ┆ [-9.6008e-02 -1.5625e-02  5.49… │\n│ sp|A0A7E6FSU6|OXDD_OCTVU ┆ [-3.0200e-01 -1.5735e-01  1.91… │\n└──────────────────────────┴─────────────────────────────────┘\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def get_simple_accession(full_id):\n    \"\"\"Strips a UniProt ID like 'sp|D3ZHV2|MACF1_RAT' to 'D3ZHV2'.\"\"\"\n    parts = full_id.split('|')\n    if len(parts) == 3:\n        return parts[1]\n    return full_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:31:44.951882Z","iopub.execute_input":"2025-11-27T05:31:44.952466Z","iopub.status.idle":"2025-11-27T05:31:44.956402Z","shell.execute_reply.started":"2025-11-27T05:31:44.952439Z","shell.execute_reply":"2025-11-27T05:31:44.955778Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(embeddings_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:35:47.279663Z","iopub.execute_input":"2025-11-27T05:35:47.279959Z","iopub.status.idle":"2025-11-27T05:35:47.291106Z","shell.execute_reply.started":"2025-11-27T05:35:47.279936Z","shell.execute_reply":"2025-11-27T05:35:47.290333Z"}},"outputs":[{"name":"stdout","text":"shape: (5, 2)\n┌──────────────────────────┬─────────────────────────────────┐\n│ Sequence_ID              ┆ Embedding                       │\n│ ---                      ┆ ---                             │\n│ str                      ┆ object                          │\n╞══════════════════════════╪═════════════════════════════════╡\n│ sp|D3ZHV2|MACF1_RAT      ┆ [-1.1731e-01 -1.2988e-01  3.58… │\n│ sp|Q6NLB0|GSTL1_ARATH    ┆ [-1.7563e-02 -1.1700e-01  1.25… │\n│ sp|P82233|BR1A_RANTE     ┆ [-4.3030e-02 -1.8921e-02  2.26… │\n│ sp|Q6P5F6|S39AA_MOUSE    ┆ [-9.6008e-02 -1.5625e-02  5.49… │\n│ sp|A0A7E6FSU6|OXDD_OCTVU ┆ [-3.0200e-01 -1.5735e-01  1.91… │\n└──────────────────────────┴─────────────────────────────────┘\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"embeddings_df = embeddings_df.with_columns(\n    pl.col(\"Sequence_ID\")\n      .str.split(\"|\") \n      .alias(\"Sequence_ID_parts\")\n)\nprint(embeddings_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:39:26.699400Z","iopub.execute_input":"2025-11-27T05:39:26.699719Z","iopub.status.idle":"2025-11-27T05:39:26.737885Z","shell.execute_reply.started":"2025-11-27T05:39:26.699698Z","shell.execute_reply":"2025-11-27T05:39:26.737329Z"}},"outputs":[{"name":"stdout","text":"shape: (5, 3)\n┌──────────────────────────┬─────────────────────────────────┬─────────────────────────────────┐\n│ Sequence_ID              ┆ Embedding                       ┆ Sequence_ID_parts               │\n│ ---                      ┆ ---                             ┆ ---                             │\n│ str                      ┆ object                          ┆ list[str]                       │\n╞══════════════════════════╪═════════════════════════════════╪═════════════════════════════════╡\n│ sp|D3ZHV2|MACF1_RAT      ┆ [-1.1731e-01 -1.2988e-01  3.58… ┆ [\"sp\", \"D3ZHV2\", \"MACF1_RAT\"]   │\n│ sp|Q6NLB0|GSTL1_ARATH    ┆ [-1.7563e-02 -1.1700e-01  1.25… ┆ [\"sp\", \"Q6NLB0\", \"GSTL1_ARATH\"… │\n│ sp|P82233|BR1A_RANTE     ┆ [-4.3030e-02 -1.8921e-02  2.26… ┆ [\"sp\", \"P82233\", \"BR1A_RANTE\"]  │\n│ sp|Q6P5F6|S39AA_MOUSE    ┆ [-9.6008e-02 -1.5625e-02  5.49… ┆ [\"sp\", \"Q6P5F6\", \"S39AA_MOUSE\"… │\n│ sp|A0A7E6FSU6|OXDD_OCTVU ┆ [-3.0200e-01 -1.5735e-01  1.91… ┆ [\"sp\", \"A0A7E6FSU6\", \"OXDD_OCT… │\n└──────────────────────────┴─────────────────────────────────┴─────────────────────────────────┘\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"embeddings_df = embeddings_df.with_columns(\n    pl.col(\"Sequence_ID_parts\").list.get(1).alias(\"protein_accession_id\")\n)\nprint(embeddings_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:41:56.897700Z","iopub.execute_input":"2025-11-27T05:41:56.898295Z","iopub.status.idle":"2025-11-27T05:41:56.924789Z","shell.execute_reply.started":"2025-11-27T05:41:56.898269Z","shell.execute_reply":"2025-11-27T05:41:56.924157Z"}},"outputs":[{"name":"stdout","text":"shape: (5, 4)\n┌──────────────────────────┬────────────────────┬──────────────────────┬──────────────────────┐\n│ Sequence_ID              ┆ Embedding          ┆ Sequence_ID_parts    ┆ protein_accession_id │\n│ ---                      ┆ ---                ┆ ---                  ┆ ---                  │\n│ str                      ┆ object             ┆ list[str]            ┆ str                  │\n╞══════════════════════════╪════════════════════╪══════════════════════╪══════════════════════╡\n│ sp|D3ZHV2|MACF1_RAT      ┆ [-1.1731e-01       ┆ [\"sp\", \"D3ZHV2\",     ┆ D3ZHV2               │\n│                          ┆ -1.2988e-01  3.58… ┆ \"MACF1_RAT\"]         ┆                      │\n│ sp|Q6NLB0|GSTL1_ARATH    ┆ [-1.7563e-02       ┆ [\"sp\", \"Q6NLB0\",     ┆ Q6NLB0               │\n│                          ┆ -1.1700e-01  1.25… ┆ \"GSTL1_ARATH\"…       ┆                      │\n│ sp|P82233|BR1A_RANTE     ┆ [-4.3030e-02       ┆ [\"sp\", \"P82233\",     ┆ P82233               │\n│                          ┆ -1.8921e-02  2.26… ┆ \"BR1A_RANTE\"]        ┆                      │\n│ sp|Q6P5F6|S39AA_MOUSE    ┆ [-9.6008e-02       ┆ [\"sp\", \"Q6P5F6\",     ┆ Q6P5F6               │\n│                          ┆ -1.5625e-02  5.49… ┆ \"S39AA_MOUSE\"…       ┆                      │\n│ sp|A0A7E6FSU6|OXDD_OCTVU ┆ [-3.0200e-01       ┆ [\"sp\", \"A0A7E6FSU6\", ┆ A0A7E6FSU6           │\n│                          ┆ -1.5735e-01  1.91… ┆ \"OXDD_OCT…           ┆                      │\n└──────────────────────────┴────────────────────┴──────────────────────┴──────────────────────┘\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# You can then cast the embedding column as before\nembeddings_df_final = embeddings_df.with_columns(\n    pl.col(\"Embedding\").list.to_array()\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:44:58.712582Z","iopub.execute_input":"2025-11-27T05:44:58.713518Z","iopub.status.idle":"2025-11-27T05:44:58.734573Z","shell.execute_reply.started":"2025-11-27T05:44:58.713483Z","shell.execute_reply":"2025-11-27T05:44:58.733661Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2068256692.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# You can then cast the embedding column as before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m embeddings_df_final = embeddings_df.with_columns(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Embedding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n","\u001b[0;31mTypeError\u001b[0m: ExprListNameSpace.to_array() missing 1 required positional argument: 'width'"],"ename":"TypeError","evalue":"ExprListNameSpace.to_array() missing 1 required positional argument: 'width'","output_type":"error"}],"execution_count":28},{"cell_type":"code","source":"embeddings_df.write_parquet('train_protein_features_esm2.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:29:12.261388Z","iopub.execute_input":"2025-11-27T05:29:12.262202Z","iopub.status.idle":"2025-11-27T05:29:12.335540Z","shell.execute_reply.started":"2025-11-27T05:29:12.262174Z","shell.execute_reply":"2025-11-27T05:29:12.334700Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mComputeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/4138374375.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_protein_features_esm2.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/polars/dataframe/frame.py\u001b[0m in \u001b[0;36mwrite_parquet\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4052\u001b[0m             \u001b[0mpartition_by\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpartition_by\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4054\u001b[0;31m         self._df.write_parquet(\n\u001b[0m\u001b[1;32m   4055\u001b[0m             \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4056\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mComputeError\u001b[0m: cannot write 'Object' datatype to parquet"],"ename":"ComputeError","evalue":"cannot write 'Object' datatype to parquet","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}